---
layout: default
title: Introduci√≥n ao Big Data
---

# Introduci√≥n **Big Data**

---
## 1. Que √© o Big Data?

**Big Data** ref√≠rese ao conxunto de datos que, polo seu **volume**, **variedade** e **velocidade** de xeraci√≥n, superan as capacidades das ferramentas tradicionais de procesamento e an√°lise.

Non se trata s√≥ da cantidade de datos, sen√≥n de como xestionalos, procesalos e extraer valor deles.

### As 5 V's do Big Data
A√≠nda que ao principio eran 3, agora consid√©rase que estas son as 5 caracter√≠sticas fundamentais que definen un sistema *Big Data*:

| V              | Significado                                                                          |
| -------------- | ------------------------------------------------------------------------------------ |
| **Volume**     | Grandes cantidades de datos (terabytes, petabytes‚Ä¶).                                 |
| **Velocidade** | Xeraci√≥n e procesamento de datos en tempo real ou case real.                         |
| **Variedade**  | Datos estruturados, semiestruturados (XML, JSON) e non estruturados (v√≠deo, texto‚Ä¶). |
| **Veracidade** | Fiabilidade, calidade e consistencia dos datos.                                      |
| **Valor**      | Capacidade de obter co√±ecemento √∫til ou predici√≥ns a partir dos datos.               |

### A orixe do Big Data
Estas son as raz√≥ns que impulsaron o nacemento do **Big Data**:
- A dixitalizaci√≥n masiva (m√≥biles, sensores, redes sociais...).
- A necesidade de tomar decisi√≥ns baseadas en datos (data-driven).
- A aparici√≥n de tecnolox√≠as "baratas" de almacenamento e procesamento distribu√≠do.

### Arquitectura t√≠pica dun sistema Big Data
1. **Inxesta de datos**: Captaci√≥n de datos dende m√∫ltiples fontes: webes, sensores, APIs...).
2. **Almacenamento**: Gardar datos nun formato escalable, normalmente distribu√≠do (*HDFS*, *S3*, *Delta Lake*...).
3. **Procesamento**: Limpeza, transformaci√≥n e an√°lise de datos (*Apache Spark*, *Apache Beam*, *Apache Flink*...).
4. **Visualizaci√≥n**: Creaci√≥n de informes e dashboards (*Power BI*, *Tableau*, *Superset*...).
5. **Gobernanza/orquestraci√≥n**: Control de acceso, seguridade, calidade de datos (*Apache Airflow*, *Apache Nifi*, *Ozie*...).
![Arquitectura](images/arquitectura-bd.png)
### Retos do Big Data
A d√≠a de hoxe, estes son os principais retos do **Big Data**:
- Escalabilidade e rendemento.
- Garantir a calidade dos datos.
- Protexer a privacidade e a seguridade.
- Xestionar a complexidade das infraestruturas.
- Interpretar correctamente os resultados.
![Os retos do Big Data](images/big-data-cloud-based-solution.webp)
## 2. Contexto: profesi√≥ns e perf√≠s relacionados cos datos

A xesti√≥n de grandes volumes de datos non √© un fin en si mesmo, sen√≥n un medio para obter informaci√≥n, tomar decisi√≥ns mellores ou automatizar procesos. Neste contexto existen distintos **perf√≠s profesionais** que traballan con datos:

### Analista de datos (*Data Analyst*)
- Usa ferramentas como Excel, SQL ou Power BI para responder preguntas de negocio.
- Explora, visualiza e comunica resultados.
- Traballa sobre datos xa limpos e preparados.

### Enxe√±eiro/a de datos (*Data Engineer*)
- Constr√∫e a infraestrutura para que os datos poidan ser almacenados, procesados e consumidos.
- Usa ferramentas como Spark, Kafka, Airflow, HDFS...
- Enc√°rgase da calidade, integridade e dispo√±ibilidade dos datos.

### Cient√≠fico/a de datos (*Data Scientist*)
- Aplica modelos estat√≠sticos ou de *machine learning* para descubrir patr√≥ns ou facer predici√≥ns.
- Usa Python, R, notebooks, bibliotecas de IA.
- Precisa datos preparados previamente pola enxe√±ar√≠a de datos.

> Neste m√≥dulo imos traballar sobre todo as tarefas propias da **enxe√±ar√≠a de datos**, pero tocando tam√©n parte do traballo anal√≠tico.

---

## 3. Tecnolox√≠as que imos empregar (e alternativas por categor√≠a)

### Almacenamento distribu√≠do
**Ferramentas do curso**:
- **HDFS** ‚Äì sistema de ficheiros distribu√≠do, tolerante a fallos.
- **MinIO** ‚Äì almacenamento obxectual compatible con Amazon S3.

**Outras alternativas**:
- Amazon S3, Azure Data Lake, Google Cloud Storage, Ceph.

---

### Procesamento de datos
**Ferramenta principal**:
- **Apache Spark** (PySpark): para procesamento batch, SQL e streaming.

**Alternativas co√±ecidas**:
- Apache Flink, Apache Beam, Hive, Presto, Dask.

---

### Inxesti√≥n e fluxo de datos
**Ferramentas empregadas**:
- **Apache NiFi** ‚Äì dese√±o gr√°fico de fluxos de datos.
- **Apache Airflow** ‚Äì planificaci√≥n e orquestraci√≥n de tarefas.

**Alternativas populares**:
- Talend, StreamSets, Dagster, Data Factory, AWS Glue.

---

### Comunicaci√≥n entre sistemas
**Ferramenta opcional e avanzada**:
- **Apache Kafka** ‚Äì mensaxer√≠a distribu√≠da para arquitecturas orientadas a eventos.

**Outras opci√≥ns**:
- RabbitMQ, Pulsar, MQTT, EventHub, Pub/Sub.

---

### Visualizaci√≥n e exploraci√≥n de datos
**Ferramentas que imos usar**:
- **Superset** / **Metabase** ‚Äì dashboards sobre datos SQL.
- **JupyterLab** ‚Äì an√°lise en Python con Pandas e visualizaci√≥ns.

**Alternativas comerciais**:
- Power BI, Tableau, Looker, QuickSight.

---

## 4. D√∫as opci√≥ns arquitect√≥nicas: soluci√≥n comercial ou personalizada

| Opci√≥n                           | Caracter√≠sticas                                                  | Vantaxes                                                | Riscos ou custos                                    |
|----------------------------------|------------------------------------------------------------------|---------------------------------------------------------|-----------------------------------------------------|
| **Soluci√≥n comercial integral** | Plataforma unificada na nube con servizos integrados             | Sinxeleza, rapidez de posta en marcha, rendemento alto | Custos por uso, dependencia do provedor             |
| **Arquitectura personalizada**  | Montaxe combinada con ferramentas libres e autoaloxadas          | Control total, aprendizaxe profunda, custo baixo       | Complexidade inicial, mantemento                   |

> üîß No curso imos constru√≠r unha **arquitectura personalizada**, que permita ao alumnado:
> - Entender cada compo√±ente tecnol√≥xico.
> - Adaptarse m√°is tarde a plataformas comerciais como Databricks, Fabric ou Confluent.

---

## 5. Soluci√≥ns comerciais end-to-end: descrici√≥n e relaci√≥n coas tecnolox√≠as

### üîπ Databricks
- Plataforma cloud creada polos fundadores de Apache Spark.
- Baseada nun modelo *Lakehouse*: datos en bruto e refinados no mesmo sistema.
- Incorpora: Spark, Delta Lake, clusters autoxestionados, notebooks, MLflow, orquestraci√≥n.
- **Tecnolox√≠as similares vistas no curso**: Spark, MinIO/HDFS, Airflow, Superset.

---

### üîπ Microsoft Fabric
- Plataforma unificada de datos dentro do ecosistema Microsoft 365.
- Incl√∫e: OneLake, Data Factory, Power BI, Notebooks, Spark engine.
- **Tecnolox√≠as similares vistas no curso**: MinIO, NiFi, Airflow, Spark, Superset.

---

### üîπ Google Cloud Platform
- Ecosistema baseado en BigQuery (DWH), Dataflow (Apache Beam), Looker (BI).
- Incorpora tam√©n Pub/Sub (streaming).
- **Tecnolox√≠as similares vistas no curso**: Spark (substitu√≠do por Beam), Kafka, Superset, Airflow.

---

### üîπ Amazon Web Services
- Plataforma modular: S3 (almacenamento), Glue (ETL), Redshift (DWH), QuickSight (BI).
- Incl√∫e MSK (Kafka xestionado).
- **Tecnolox√≠as similares vistas no curso**: MinIO, NiFi, Airflow, Spark, Kafka, Superset.

---

### üîπ Confluent Platform
- Versi√≥n empresarial de Apache Kafka.
- Incorpora: Kafka Connect, KSQL, Schema Registry, Control Center.
- Foco en arquitecturas orientadas a eventos en tempo real.
- **Tecnolox√≠as similares vistas no curso**: Kafka, NiFi, Airflow.

---

### T√°boa comparativa

| Plataforma        | Almacenamento | Procesamento | Inxesti√≥n / ETL      | Visualizaci√≥n BI | Streaming / eventos |
|------------------|----------------|--------------|-----------------------|------------------|----------------------|
| Databricks       | ADLS / S3      | ‚úî Spark      | ‚úî Pipelines propios   | ‚úî Dashboards     | ‚úî Kafka integrado    |
| MS Fabric        | OneLake        | ‚úî Spark      | ‚úî Data Factory        | ‚úî Power BI       | EventHub (parcial)   |
| GCP              | GCS            | ‚úî Beam       | ‚úî Dataflow            | ‚úî Looker         | ‚úî Pub/Sub            |
| AWS              | S3             | ‚úî Spark      | ‚úî Glue                | ‚úî QuickSight     | ‚úî MSK (Kafka)        |
| Confluent        | Externo (S3‚Ä¶)  | ‚úñ            | ‚úî Kafka Connect       | Opcional         | ‚úî Kafka completo     |

---

## 6. Ferramentas e contidos que se van desenvolver no curso

| Categor√≠a              | Ferramentas ou contidos inclu√≠dos                          | Obxectivo no curso                                                 |
|------------------------|-------------------------------------------------------------|---------------------------------------------------------------------|
| Almacenamento          | HDFS, MinIO                                                  | Comprender almacenamento distribu√≠do e obxectual                   |
| Procesamento batch     | Apache Spark + PySpark                                       | ETL e an√°lises distribu√≠das con RDDs e DataFrames                  |
| Procesamento streaming | Spark Structured Streaming + fontes reais (Kafka ou APIs)   | An√°lise de datos en tempo real                                     |
| Inxesti√≥n / ETL        | Apache NiFi, Airflow                                         | Automatizaci√≥n de extracci√≥n e carga de datos                     |
| Comunicaci√≥n           | Apache Kafka (teor√≠a e pr√°ctica opcional)                   | Sistemas orientados a eventos, logs distribu√≠dos                   |
| Visualizaci√≥n          | Superset / Metabase, JupyterLab                             | Dashboards e an√°lise exploratoria                                  |
| Orquestraci√≥n          | Airflow, NiFi                                                | Dependencias, planificaci√≥n e control de execuci√≥n de pipelines    |
| BI / an√°lise final     | Power BI (observaci√≥n), Superset (uso pr√°ctico)              | Comparativa real entre alternativas libres e comerciais             |

## 7. Glosario de termos
### Almacenamento
- **Data lake**: Repositorio de almacenamento masivo onde se gardan datos en bruto en calquera formato (non estruturados e semi-estruturados).
- **Data Warehouse**: Almac√©n de datos estruturados, dese√±ado para a an√°lise e a toma de decisi√≥ns. Habitualmente con topolox√≠a en estrela.
- **Delta Lake**: Capa transaccional ACID sobre un data lake que garante calidade, consistencia e control
- **Delta Table**:	T√°boa en formato Delta con capacidades avanzadas de consulta e modificaci√≥n de datos
### Procesamento de datos
- **Batch Processing**: Procesamento de datos en bloques ou lotes, con latencia alta pero bo rendemento para grandes volumes.
- **Streaming Processing**: Procesamento en tempo real de fluxos de datos continuamente xerados.
- **ETL (Extract, Transform, Load)**: Proceso cl√°sico de extracci√≥n, transformaci√≥n e carga de datos.
- **ELT (Extract, Load, Transform)**: Variante moderna onde os datos se cargan primeiro e logo se transforman no destino.
### An√°lise e ciencia de datos
- **DataFrame**: Estrutura de datos tabular usada en Spark e Pandas.
- **Data Profiling**: T√©cnica para analizar a estrutura, calidade e estat√≠sticas dos datos.
- **Feature Engineering**: Proceso de transformaci√≥n de datos en caracter√≠sticas relevantes para modelos de aprendizaxe autom√°tica.
- **Model Deployment**: Fase de despregue dun modelo para que poida ser usado en produci√≥n.
### Visualizaci√≥n e ciencia de datos
- **Dashboard**: Panel visual que presenta indicadores clave e m√©tricas en tempo real.
- **KPIs (Key Performance Indicators)**: M√©tricas cr√≠ticas que indican o rendemento dos procesos de negocio.
### Calidade, monitorizaci√≥n e seguridade
- **Data Lineage**: Seguimento da orixe e transformaci√≥n dos datos ao longo do seu ciclo de vida.
- **Observabilidade de datos**: Capacidade de rastrear, monitorizar e alertar sobre problemas nos fluxos de datos.
- **Data Governance**: Pol√≠ticas e pr√°cticas para asegurar o uso responsable, seguro e legal dos datos.
- **DLP (Data Loss Prevention)**: Conxunto de ferramentas para evitar a fuga de informaci√≥n sensible.
### Arquitectura
- **Lambda Architecture**: Modelo que combina procesamento batch e streaming para unha an√°lise m√°is completa.
- **Kappa Architecture**: Variante que usa s√≥ fluxos de datos en tempo real, simplificando o dese√±o.
- **Medallion Architecture**: Arquitectura por capas (bronze, silver, gold) para mellorar a calidade dos datos progresivamente.
### Outros conceptos
- **Metadata**: Datos que describen outros datos (estructura, tipo, fonte...).
- **Schema Evolution**: Capacidade dun sistema para adaptar cambios no esquema dos datos.
- **Partitioning**: T√©cnica para dividir grandes conxuntos de datos en subconxuntos m√°is pequenos para mellorar o rendemento.
- **Shuffling**: Redistribuci√≥n de datos entre tarefas no proceso de agrupaci√≥n ou combinaci√≥n en Spark.
